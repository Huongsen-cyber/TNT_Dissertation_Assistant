import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
from docx import Document
from io import BytesIO

# --- TH∆Ø VI·ªÜN X·ª¨ L√ù GI·ªåNG N√ìI ---
from streamlit_mic_recorder import mic_recorder
import speech_recognition as sr
from gtts import gTTS
import tempfile
import os
from pydub import AudioSegment # Th∆∞ vi·ªán m·ªõi ƒë·ªÉ chuy·ªÉn ƒë·ªïi √¢m thanh
# --------------------------------

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(
    page_title="Dissertation Master AI (Pro Max)",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- H√ÄM X·ª¨ L√ù FILE PDF ---
def get_pdf_text(uploaded_file):
    try:
        reader = PdfReader(uploaded_file)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return f"L·ªói ƒë·ªçc file: {e}"

# --- SIDEBAR ---
with st.sidebar:
    st.title("üéôÔ∏è C·∫•u h√¨nh & Voice")
    
    api_key = st.text_input("Nh·∫≠p Google AI API Key:", type="password")
    
    if api_key:
        if st.button("üî¥ Ki·ªÉm tra Model"):
            try:
                genai.configure(api_key=api_key)
                models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
                st.code(models)
            except:
                pass

    st.divider()
    
    # --- KHU V·ª∞C VOICE CHAT ---
    st.subheader("üé§ Voice Chat")
    st.info("Nh·∫•n n√∫t ƒë·ªè ƒë·ªÉ n√≥i:")
    
    # Widget ghi √¢m
    audio_bytes = mic_recorder(
        start_prompt="üî¥ B·∫•m ƒë·ªÉ Ghi √¢m",
        stop_prompt="‚èπÔ∏è B·∫•m ƒë·ªÉ D·ª´ng",
        just_once=True,
        key='recorder'
    )
    # --------------------------
    
    st.divider()
    
    work_mode = st.radio(
        "Quy tr√¨nh x·ª≠ l√Ω:",
        ["Research (Nghi√™n c·ª©u)", "Drafting (Vi·∫øt nh√°p)", "Academic Review (Ph·∫£n bi·ªán)", "LaTeX Conversion"]
    )
    
    st.divider()
    
    st.subheader("üìÇ T√†i li·ªáu tham kh·∫£o")
    uploaded_files = st.file_uploader("T·∫£i l√™n PDF:", type="pdf", accept_multiple_files=True)
    
    context_text = ""
    if uploaded_files:
        with st.spinner("ƒêang ƒë·ªçc t√†i li·ªáu..."):
            for pdf in uploaded_files:
                text = get_pdf_text(pdf)
                context_text += f"\n--- T√ÄI LI·ªÜU: {pdf.name} ---\n{text}\n"
            st.success(f"ƒê√£ n·∫°p {len(uploaded_files)} file!")

# --- SYSTEM PROMPT ---
base_instruction = """
B·∫°n l√† 'Dissertation Master AI', tr·ª£ l√Ω h·ªçc thu·∫≠t chuy√™n s√¢u.
Nhi·ªám v·ª•: H·ªó tr·ª£ vi·∫øt, ph·∫£n bi·ªán v√† ƒë·ªãnh d·∫°ng lu·∫≠n vƒÉn khoa h·ªçc.
QUY T·∫ÆC: Academic Tone, Evidence-Based, LaTeX format.
"""
if work_mode == "LaTeX Conversion":
    system_instruction = base_instruction + "\nNhi·ªám v·ª•: Chuy·ªÉn ƒë·ªïi sang LaTeX chu·∫©n Overleaf."
elif work_mode == "Academic Review (Ph·∫£n bi·ªán)":
    system_instruction = base_instruction + "\nNhi·ªám v·ª•: ƒê√≥ng vai Reviewer kh√≥ t√≠nh."
else:
    system_instruction = base_instruction

if context_text:
    system_instruction += f"\n\nCONTEXT T·ª™ PDF:\n{context_text}"

# --- SESSION STATE ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- GIAO DI·ªÜN CH√çNH ---
st.title("üéì Dissertation Master AI (Voice Edition)")
st.caption("H·ªó tr·ª£: ƒê·ªçc PDF | Xu·∫•t Word | Tr√≤ chuy·ªán Gi·ªçng n√≥i | ƒê·ªçc vƒÉn b·∫£n cho ng∆∞·ªùi khi·∫øm th·ªã")
st.markdown("---")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- X·ª¨ L√ù INPUT (∆ØU TI√äN GI·ªåNG N√ìI TR∆Ø·ªöC) ---
prompt = None

# 1. Ki·ªÉm tra xem c√≥ d·ªØ li·ªáu √¢m thanh t·ª´ Sidebar kh√¥ng
if audio_bytes and audio_bytes['bytes']:
    with st.spinner("üéß ƒêang x·ª≠ l√Ω √¢m thanh..."):
        try:
            # B∆Ø·ªöC QUAN TR·ªåNG: CHUY·ªÇN ƒê·ªîI ƒê·ªäNH D·∫†NG √ÇM THANH
            # 1. L∆∞u file g·ªëc (th∆∞·ªùng l√† WebM)
            with tempfile.NamedTemporaryFile(delete=False, suffix=".webm") as temp_webm:
                temp_webm.write(audio_bytes['bytes'])
                temp_webm_path = temp_webm.name

            # 2. Chuy·ªÉn ƒë·ªïi sang WAV b·∫±ng Pydub
            wav_path = temp_webm_path.replace(".webm", ".wav")
            audio = AudioSegment.from_file(temp_webm_path)
            audio.export(wav_path, format="wav")

            # 3. D√πng SpeechRecognition ƒë·ªçc file WAV
            recognizer = sr.Recognizer()
            with sr.AudioFile(wav_path) as source:
                audio_data = recognizer.record(source)
                # Nh·∫≠n di·ªán ti·∫øng Vi·ªát
                voice_text = recognizer.recognize_google(audio_data, language="vi-VN")
                prompt = voice_text 
            
            # D·ªçn d·∫πp file r√°c
            os.remove(temp_webm_path)
            os.remove(wav_path)

        except Exception as e:
            st.warning(f"Kh√¥ng nghe r√µ ho·∫∑c l·ªói ƒë·ªãnh d·∫°ng: {e}")

# 2. N·∫øu kh√¥ng n√≥i, th√¨ ki·ªÉm tra √¥ chat nh·∫≠p ph√≠m
if not prompt:
    prompt = st.chat_input("H·ªèi v·ªÅ t√†i li·ªáu ho·∫∑c y√™u c·∫ßu vi·∫øt...")

# --- X·ª¨ L√ù CHAT & TR·∫¢ L·ªúI ---
if prompt:
    if not api_key:
        st.error("‚ö†Ô∏è Ch∆∞a nh·∫≠p API Key!")
        st.stop()
        
    genai.configure(api_key=api_key)
    
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            model = genai.GenerativeModel(
                model_name="models/gemini-2.0-flash", 
                system_instruction=system_instruction
            )
            
            chat_history = [{"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages if m["role"] != "system"]
            chat = model.start_chat(history=chat_history)
            response = chat.send_message(prompt, stream=True)
            
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "‚ñå")
            
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})

            # --- T√çNH NƒÇNG 1: T·∫†O FILE WORD ---
            doc = Document()
            doc.add_heading('Dissertation Assistant Draft', 0)
            doc.add_paragraph(full_response)
            bio = BytesIO()
            doc.save(bio)
            
            col1, col2 = st.columns([1, 1])
            with col1:
                st.download_button(
                    label="üì• T·∫£i Word (.docx)",
                    data=bio.getvalue(),
                    file_name="Luan_van_draft.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
            
            # --- T√çNH NƒÇNG 2: ƒê·ªåC TH√ÄNH TI·∫æNG (TTS) ---
            with col2:
                try:
                    with st.spinner("üîä ƒêang t·∫°o gi·ªçng ƒë·ªçc..."):
                        tts = gTTS(text=full_response, lang='vi')
                        mp3_fp = BytesIO()
                        tts.write_to_fp(mp3_fp)
                        st.audio(mp3_fp, format='audio/mp3')
                except Exception as e:
                    st.error(f"L·ªói t·∫°o √¢m thanh: {e}")

        except Exception as e:
            st.error(f"L·ªói: {e}")