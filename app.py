import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
from docx import Document
from io import BytesIO

# --- TH∆Ø VI·ªÜN X·ª¨ L√ù GI·ªåNG N√ìI ---
from streamlit_mic_recorder import mic_recorder
import speech_recognition as sr
from gtts import gTTS
import tempfile
import os
# --------------------------------

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(
    page_title="Dissertation Master AI (Pro Max)",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- H√ÄM X·ª¨ L√ù FILE PDF ---
def get_pdf_text(uploaded_file):
    try:
        reader = PdfReader(uploaded_file)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return f"L·ªói ƒë·ªçc file: {e}"

# --- SIDEBAR ---
with st.sidebar:
    st.title("üéôÔ∏è C·∫•u h√¨nh & Voice")
    
    api_key = st.text_input("Nh·∫≠p Google AI API Key:", type="password")
    
    st.divider()
    
    # --- KHU V·ª∞C VOICE CHAT (M·ªöI) ---
    st.subheader("üé§ Voice Chat")
    st.info("Nh·∫•n n√∫t b√™n d∆∞·ªõi ƒë·ªÉ n√≥i (thay v√¨ g√µ ph√≠m)")
    
    # Widget ghi √¢m
    audio_bytes = mic_recorder(
        start_prompt="üî¥ B·∫•m ƒë·ªÉ Ghi √¢m",
        stop_prompt="‚èπÔ∏è B·∫•m ƒë·ªÉ D·ª´ng",
        just_once=True,
        key='recorder'
    )
    # --------------------------------
    
    st.divider()
    
    # 1. Ch·∫ø ƒë·ªô
    work_mode = st.radio(
        "Quy tr√¨nh x·ª≠ l√Ω:",
        ["Research (Nghi√™n c·ª©u)", "Drafting (Vi·∫øt nh√°p)", "Academic Review (Ph·∫£n bi·ªán)", "LaTeX Conversion"]
    )
    
    st.divider()
    
    # 2. Upload
    st.subheader("üìÇ T√†i li·ªáu tham kh·∫£o")
    uploaded_files = st.file_uploader("T·∫£i l√™n PDF:", type="pdf", accept_multiple_files=True)
    
    context_text = ""
    if uploaded_files:
        with st.spinner("ƒêang ƒë·ªçc t√†i li·ªáu..."):
            for pdf in uploaded_files:
                text = get_pdf_text(pdf)
                context_text += f"\n--- T√ÄI LI·ªÜU: {pdf.name} ---\n{text}\n"
            st.success(f"ƒê√£ n·∫°p {len(uploaded_files)} file!")

# --- SYSTEM PROMPT ---
base_instruction = """
B·∫°n l√† 'Dissertation Master AI', tr·ª£ l√Ω h·ªçc thu·∫≠t chuy√™n s√¢u.
Nhi·ªám v·ª•: H·ªó tr·ª£ vi·∫øt, ph·∫£n bi·ªán v√† ƒë·ªãnh d·∫°ng lu·∫≠n vƒÉn khoa h·ªçc.
QUY T·∫ÆC: Academic Tone, Evidence-Based, LaTeX format.
"""
if work_mode == "LaTeX Conversion":
    system_instruction = base_instruction + "\nNhi·ªám v·ª•: Chuy·ªÉn ƒë·ªïi sang LaTeX chu·∫©n Overleaf."
elif work_mode == "Academic Review (Ph·∫£n bi·ªán)":
    system_instruction = base_instruction + "\nNhi·ªám v·ª•: ƒê√≥ng vai Reviewer kh√≥ t√≠nh."
else:
    system_instruction = base_instruction

if context_text:
    system_instruction += f"\n\nCONTEXT T·ª™ PDF:\n{context_text}"

# --- SESSION STATE ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- GIAO DI·ªÜN CH√çNH ---
st.title("üéì Dissertation Master AI (Voice Edition)")
st.caption("H·ªó tr·ª£: ƒê·ªçc PDF | Xu·∫•t Word | Tr√≤ chuy·ªán Gi·ªçng n√≥i")
st.markdown("---")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- X·ª¨ L√ù INPUT (∆ØU TI√äN GI·ªåNG N√ìI TR∆Ø·ªöC) ---
prompt = None

# 1. Ki·ªÉm tra xem c√≥ d·ªØ li·ªáu √¢m thanh t·ª´ Sidebar kh√¥ng
if audio_bytes and audio_bytes['bytes']:
    with st.spinner("üéß ƒêang nghe b·∫°n n√≥i..."):
        # L∆∞u file t·∫°m ƒë·ªÉ th∆∞ vi·ªán SpeechRecognition ƒë·ªçc
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_audio:
            temp_audio.write(audio_bytes['bytes'])
            temp_audio_path = temp_audio.name
        
        # D√πng Google ƒë·ªÉ chuy·ªÉn √Çm thanh -> VƒÉn b·∫£n
        recognizer = sr.Recognizer()
        with sr.AudioFile(temp_audio_path) as source:
            audio_data = recognizer.record(source)
            try:
                # Nh·∫≠n di·ªán ti·∫øng Vi·ªát
                voice_text = recognizer.recognize_google(audio_data, language="vi-VN")
                prompt = voice_text # G√°n vƒÉn b·∫£n n√≥i v√†o bi·∫øn prompt
                # X√≥a file t·∫°m
                os.remove(temp_audio_path)
            except Exception as e:
                st.warning("Kh√¥ng nghe r√µ, vui l√≤ng n√≥i l·∫°i ho·∫∑c g√µ ph√≠m.")

# 2. N·∫øu kh√¥ng n√≥i, th√¨ ki·ªÉm tra √¥ chat nh·∫≠p ph√≠m
if not prompt:
    prompt = st.chat_input("H·ªèi v·ªÅ t√†i li·ªáu ho·∫∑c y√™u c·∫ßu vi·∫øt...")

# --- X·ª¨ L√ù CHAT & TR·∫¢ L·ªúI ---
if prompt:
    if not api_key:
        st.error("‚ö†Ô∏è Ch∆∞a nh·∫≠p API Key!")
        st.stop()
        
    genai.configure(api_key=api_key)
    
    # Hi·ªÉn th·ªã c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AI Tr·∫£ l·ªùi
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # D√πng model x·ªãn nh·∫•t b·∫°n c√≥
            model = genai.GenerativeModel(
                model_name="models/gemini-2.0-flash", 
                system_instruction=system_instruction
            )
            
            chat_history = [{"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages if m["role"] != "system"]
            chat = model.start_chat(history=chat_history)
            response = chat.send_message(prompt, stream=True)
            
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "‚ñå")
            
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})

            # --- T√çNH NƒÇNG 1: T·∫†O FILE WORD ---
            doc = Document()
            doc.add_heading('Dissertation Assistant Draft', 0)
            doc.add_paragraph(full_response)
            bio = BytesIO()
            doc.save(bio)
            
            col1, col2 = st.columns([1, 1])
            with col1:
                st.download_button(
                    label="üì• T·∫£i Word (.docx)",
                    data=bio.getvalue(),
                    file_name="Luan_van_draft.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
            
            # --- T√çNH NƒÇNG 2: ƒê·ªåC TH√ÄNH TI·∫æNG (TTS) ---
            with col2:
                # Ch·ªâ ƒë·ªçc n·∫øu vƒÉn b·∫£n kh√¥ng qu√° d√†i (ƒë·ªÉ tr√°nh l·ªói load l√¢u)
                if len(full_response) < 1000: 
                    try:
                        tts = gTTS(text=full_response, lang='vi')
                        # L∆∞u v√†o buffer b·ªô nh·ªõ thay v√¨ file c·ª©ng ƒë·ªÉ nhanh h∆°n
                        mp3_fp = BytesIO()
                        tts.write_to_fp(mp3_fp)
                        st.audio(mp3_fp, format='audio/mp3')
                    except:
                        st.info("VƒÉn b·∫£n qu√° d√†i ho·∫∑c l·ªói k·∫øt n·ªëi TTS.")
                else:
                    st.info("üîá VƒÉn b·∫£n d√†i, t·ª± ƒë·ªông t·∫Øt ƒë·ªçc ti·∫øng ƒë·ªÉ t·ªëi ∆∞u.")

        except Exception as e:
            st.error(f"L·ªói: {e}")